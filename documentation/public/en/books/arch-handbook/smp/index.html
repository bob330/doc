<!doctype html><html class=theme-light lang=en><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="SMPng Design Document"><meta name=keywords content="SMPng,introduction,locks"><meta name=copyright content="1995-2024 The FreeBSD Foundation"><link rel=canonical href=http://172.16.201.134:1313/en/books/arch-handbook/smp/><title>Chapter 8. SMPng Design Document | FreeBSD Documentation Portal</title>
<meta name=theme-color content="#790000"><meta name=color-scheme content="system light dark high-contrast"><link rel="shortcut icon" href=http://172.16.201.134:1313/favicon.ico><link rel=stylesheet href=http://172.16.201.134:1313/styles/main.min.css><link rel=stylesheet href=http://172.16.201.134:1313/css/font-awesome-min.css><script defer src=/js/theme-chooser.min.js></script><script defer src=/js/copy-clipboard.min.js></script><script defer src=/js/search.min.js></script><meta name=twitter:card content="summary"><meta name=twitter:domain content="docs.FreeBSD.org"><meta name=twitter:site content="@freebsd"><meta name=twitter:url content="https://twitter.com/freebsd"><meta property="og:title" content="Chapter 8. SMPng Design Document"><meta property="og:description" content="SMPng Design Document"><meta property="og:type" content="website"><meta property="og:image" content="http://172.16.201.134:1313/favicon.ico"><meta property="og:image:alt" content="FreeBSD Logo"><meta property="og:locale" content="en"><meta property="og:url" content="http://172.16.201.134:1313/en/books/arch-handbook/smp/"><meta property="og:site_name" content="FreeBSD Documentation Portal"><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","url":"http:\/\/172.16.201.134:1313\/en\/books\/arch-handbook\/smp\/","name":"FreeBSD Documentation Portal","headline":"FreeBSD Documentation Portal","description":"FreeBSD Documentation Portal"}</script></head><body><header><div class=header-container><div class=logo-menu-bars-container><a href=https://www.FreeBSD.org class=logo><img src=http://172.16.201.134:1313/images/FreeBSD-monochromatic.svg width=160 height=50 alt="FreeBSD logo">
</a><label class=menu-bars for=menu-bars><i class="fa fa-bars" aria-hidden=true></i></label></div><input id=menu-bars type=checkbox><nav><ul class=menu><li class=menu-item><input id=about type=checkbox>
<a href=# aria-label="Navigate to About section"><label class=menu-item-description for=about>About
<i class="fa fa-angle-down fa-lg" aria-hidden=true></i></label></a><ul class=sub-menu><li class=title><a href=https://www.freebsd.org/about/ target=_blank>About</a></li><li><a href=https://www.freebsd.org/about/ target=_blank>FreeBSD</a></li><li><a href=https://freebsdfoundation.org/about-us/about-the-foundation/ target=_blank>FreeBSD Foundation</a></li><li><a href=https://www.freebsd.org/internal/code-of-conduct/ target=_blank>Code of Conduct</a></li></ul></li><li class=menu-item><input id=download type=checkbox>
<a href=# aria-label="Navigate to get FreeBSD section"><label class=menu-item-description for=download>Get FreeBSD
<i class="fa fa-angle-down fa-lg" aria-hidden=true></i></label></a><ul class=sub-menu><li class=title><a href=https://www.freebsd.org/where/ target=_blank>Get FreeBSD</a></li><li><a href=https://www.freebsd.org/releases/ target=_blank>Release Information</a></li><li><a href=https://www.freebsd.org/releng/ target=_blank>Release Engineering</a></li><li><a href=https://www.freebsd.org/security/ target=_blank>Security Advisories</a></li></ul></li><li class=menu-item><input id=documentation type=checkbox>
<a href=# aria-label="Navigate to get Documentation section"><label class=menu-item-description for=documentation>Documentation
<i class="fa fa-angle-down fa-lg" aria-hidden=true></i></label></a><ul class=sub-menu><li class=title><a href=/en>Documentation portal</a></li><li><a href=http://172.16.201.134:1313/en/books/handbook>FreeBSD Handbook</a></li><li><a href=http://172.16.201.134:1313/en/books/porters-handbook>Porter's Handbook</a></li><li><a href=https://docs.FreeBSD.org/en/books/fdp-primer>Documentation Project Handbook</a></li><li><a href=https://man.FreeBSD.org target=_blank>Manual pages</a></li><li><a href=https://papers.FreeBSD.org target=_blank>Presentations and papers</a></li><li><a href=https://wiki.FreeBSD.org target=_blank>Wiki</a></li><li><a href=http://172.16.201.134:1313/en/books>Books</a></li><li><a href=http://172.16.201.134:1313/en/articles>Articles</a></li></ul></li><li class=menu-item><input id=community type=checkbox>
<a href=# aria-label="Navigate to get Community section"><label class=menu-item-description for=community>Community
<i class="fa fa-angle-down fa-lg" aria-hidden=true></i></label></a><ul class=sub-menu><li class=title><a href=https://www.freebsd.org/community/>Community</a></li><li><a href=http://172.16.201.134:1313/en/articles/contributing>Get involved</a></li><li><a href=https://forums.freebsd.org/ target=_blank>Forum</a></li><li><a href=https://lists.freebsd.org/ target=_blank>Mailing lists</a></li><li><a href=https://wiki.freebsd.org/IRC/Channels target=_blank>IRC Channels</a></li><li><a href=https://bugs.freebsd.org/bugzilla/ target=_blank>Bug Tracker</a></li><li><a href=https://www.freebsd.org/support/ target=_blank>Support</a></li></ul></li></ul></nav><div class=search-donate-container><form class=search method=get id=search-header-form action=https://docs.freebsd.org/search name=search-header-form><input type=hidden name=DB value=en>
<input id=words name=P type=text size=20 maxlength=255>
<button>
<i class="fa fa-search" aria-hidden=true></i></button></form><div class=donate><a href=https://freebsdfoundation.org/donate/ target=_blank><span class=heart>â™¥</span>
Donate</a></div></div></div></header><input type=checkbox class="hidden toggle" id=menu-control><main class=main-wrapper-book><a id=top></a><aside class=book-menu><div class=book-menu-content><input id=search-book type=text placeholder=Search aria-label=Search maxlength=128><nav id=MenuContents><ul><li><input type=checkbox id=chapter-6dcd22d99f78db2a9aacae23be13866e class=toggle>
<label for=chapter-6dcd22d99f78db2a9aacae23be13866e><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/parti/>Part I. Kernel</a></li><li><input type=checkbox id=chapter-9cc61bc35df69063dc03a5911e1ad9c9 class=toggle>
<label class="icon cursor" for=chapter-9cc61bc35df69063dc03a5911e1ad9c9><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/>Chapter 1. Bootstrapping and Kernel Initialization</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot-synopsis>1.1. Synopsis</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot-overview>1.2. Overview</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot-bios>1.3. The BIOS</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot-boot0>1.4. The Master Boot Record (<code>boot0</code>)</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot-boot1>1.5. <code>boot1</code> Stage</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#btx-server>1.6. The BTX Server</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot2>1.7. boot2 Stage</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot-loader>1.8. loader Stage</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/boot/#boot-kernel>1.9. Kernel Initialization</a></li></ul></li><li><input type=checkbox id=chapter-3a651b0a4b9f6238336624d3c0fa5187 class=toggle>
<label class="icon cursor" for=chapter-3a651b0a4b9f6238336624d3c0fa5187><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/locking/>Chapter 2. Locking Notes</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/locking/#locking-mutexes>2.1. Mutexes</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/locking/#locking-sx>2.2. Shared Exclusive Locks</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/locking/#locking-atomic>2.3. Atomically Protected Variables</a></li></ul></li><li><input type=checkbox id=chapter-bf0b823c107a80f3035dfd6fae09d023 class=toggle>
<label class="icon cursor" for=chapter-bf0b823c107a80f3035dfd6fae09d023><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/kobj/>Chapter 3. Kernel Objects</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/kobj/#kernel-objects-term>3.1. Terminology</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/kobj/#kernel-objects-operation>3.2. Kobj Operation</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/kobj/#kernel-objects-using>3.3. Using Kobj</a></li></ul></li><li><input type=checkbox id=chapter-41dab1afed6cf3ffa54628db4227e196 class=toggle>
<label class="icon cursor" for=chapter-41dab1afed6cf3ffa54628db4227e196><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/jail/>Chapter 4. The Jail Subsystem</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/jail/#jail-arch>4.1. Architecture</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/jail/#jail-restrictions>4.2. Restrictions</a></li></ul></li><li><input type=checkbox id=chapter-e7d9ebcb448b0045179ebe22f8e2e9d8 class=toggle>
<label class="icon cursor" for=chapter-e7d9ebcb448b0045179ebe22f8e2e9d8><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/sysinit/>Chapter 5. The SYSINIT Framework</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/sysinit/#sysinit-term>5.1. Terminology</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/sysinit/#sysinit-operation>5.2. SYSINIT Operation</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/sysinit/#sysinit-using>5.3. Using SYSINIT</a></li></ul></li><li><input type=checkbox id=chapter-8b57b16ba53538421a8fb2152b25976f class=toggle>
<label class="icon cursor" for=chapter-8b57b16ba53538421a8fb2152b25976f><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/>Chapter 6. The TrustedBSD MAC Framework</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-copyright>6.1. MAC Documentation Copyright</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-synopsis>6.2. Synopsis</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-introduction>6.3. Introduction</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-background>6.4. Policy Background</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-framework-kernel-arch>6.5. MAC Framework Kernel Architecture</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-policy-architecture>6.6. MAC Policy Architecture</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-entry-point-reference>6.7. MAC Policy Entry Point Reference</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-userland-arch>6.8. Userland Architecture</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/mac/#mac-conclusion>6.9. Conclusion</a></li></ul></li><li><input type=checkbox id=chapter-28609916419208e3a19d240cf7593906 class=toggle>
<label class="icon cursor" for=chapter-28609916419208e3a19d240cf7593906><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm/>Chapter 7. Virtual Memory System</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm/#vm-physmem>7.1. Management of Physical Memory <code>vm_page_t</code></a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm/#vm-cache>7.2. The Unified Buffer Cache <code>vm_object_t</code></a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm/#vm-fileio>7.3. Filesystem I/O <code>struct buf</code></a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm/#vm-pagetables>7.4. Mapping Page Tables <code>vm_map_t, vm_entry_t</code></a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm/#vm-kvm>7.5. KVM Memory Mapping</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm/#vm-tuning>7.6. Tuning the FreeBSD VM System</a></li></ul></li><li><input type=checkbox id=chapter-716edd44e8ad22ea57cdf273d2578872 class=toggle checked>
<label class="icon cursor" for=chapter-716edd44e8ad22ea57cdf273d2578872><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/>Chapter 8. SMPng Design Document</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/#smp-intro>8.1. Introduction</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/#smp-lock-fundamentals>8.2. Basic Tools and Locking Fundamentals</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/#smp-design>8.3. General Architecture and Design</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/#smp-lock-strategies>8.4. Specific Locking Strategies</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/#smp-implementation-notes>8.5. Implementation Notes</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/#smp-misc>8.6. Miscellaneous Topics</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/smp/#smp-glossary>Glossary</a></li></ul></li><li><input type=checkbox id=chapter-448f803e40f97b1ff8336db9ba637745 class=toggle>
<label for=chapter-448f803e40f97b1ff8336db9ba637745><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/partii/>Part II. Device Drivers</a></li><li><input type=checkbox id=chapter-6971d35b0bbe2a0bdb005a02546cd580 class=toggle>
<label class="icon cursor" for=chapter-6971d35b0bbe2a0bdb005a02546cd580><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/driverbasics/>Chapter 9. Writing FreeBSD Device Drivers</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/driverbasics/#driverbasics-intro>9.1. Introduction</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/driverbasics/#driverbasics-kld>9.2. Dynamic Kernel Linker Facility - KLD</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/driverbasics/#driverbasics-char>9.3. Character Devices</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/driverbasics/#driverbasics-block>9.4. Block Devices (Are Gone)</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/driverbasics/#driverbasics-net>9.5. Network Drivers</a></li></ul></li><li><input type=checkbox id=chapter-9cc7968be065b256e57086439d93e9a4 class=toggle>
<label class="icon cursor" for=chapter-9cc7968be065b256e57086439d93e9a4><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/>Chapter 10. ISA Device Drivers</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-synopsis>10.1. Synopsis</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-basics>10.2. Basic Information</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-device-t>10.3. <code>device_t</code> Pointer</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-config>10.4. Configuration File and the Order of Identifying and Probing During Auto-Configuration</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-resources>10.5. Resources</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-busmem>10.6. Bus Memory Mapping</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-dma>10.7. DMA</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-probe>10.8. xxx_isa_probe</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-attach>10.9. xxx_isa_attach</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-detach>10.10. xxx_isa_detach</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-shutdown>10.11. xxx_isa_shutdown</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/isa/#isa-driver-intr>10.12. xxx_intr</a></li></ul></li><li><input type=checkbox id=chapter-0b427d421e89aa3107f62d5b70f6a0f2 class=toggle>
<label class="icon cursor" for=chapter-0b427d421e89aa3107f62d5b70f6a0f2><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/pci/>Chapter 11. PCI Devices</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/pci/#pci-probe>11.1. Probe and Attach</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/pci/#pci-bus>11.2. Bus Resources</a></li></ul></li><li><input type=checkbox id=chapter-0b7eb8d45a0ea6bc9c2882e903b93959 class=toggle>
<label class="icon cursor" for=chapter-0b7eb8d45a0ea6bc9c2882e903b93959><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/>Chapter 12. Common Access Method SCSI Controllers</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#scsi-synopsis>12.1. Synopsis</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#scsi-general>12.2. General Architecture</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#_globals_and_boilerplate>12.3. Globals and Boilerplate</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#_device_configuration_xxx_attach>12.4. Device configuration: xxx_attach</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#_processing_cam_messages_xxx_action>12.5. Processing CAM messages: xxx_action</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#scsi-polling>12.6. Polling xxx_poll</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#scsi-async>12.7. Asynchronous Events</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#scsi-interrupts>12.8. Interrupts</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#scsi-errors>12.9. Errors Summary</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/scsi/#scsi-timeout>12.10. Timeout Handling</a></li></ul></li><li><input type=checkbox id=chapter-bdaa4909dfbdcec8d7be976fd87cb00e class=toggle>
<label class="icon cursor" for=chapter-bdaa4909dfbdcec8d7be976fd87cb00e><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/usb/>Chapter 13. USB Devices</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/usb/#usb-intro>13.1. Introduction</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/usb/#usb-hc>13.2. Host Controllers</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/usb/#usb-dev>13.3. USB Device Information</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/usb/#usb-devprobe>13.4. Device Probe and Attach</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/usb/#usb-protocol>13.5. USB Drivers Protocol Information</a></li></ul></li><li><input type=checkbox id=chapter-5fc5c179f5014d968a5c8feec7e10e59 class=toggle>
<label class="icon cursor" for=chapter-5fc5c179f5014d968a5c8feec7e10e59><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/newbus/>Chapter 14. Newbus</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/newbus/#newbus-devdrivers>14.1. Device Drivers</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/newbus/#newbus-overview>14.2. Overview of Newbus</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/newbus/#newbus-api>14.3. Newbus API</a></li></ul></li><li><input type=checkbox id=chapter-7d3796cced00105c77e7f87e84edd73b class=toggle>
<label class="icon cursor" for=chapter-7d3796cced00105c77e7f87e84edd73b><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/sound/>Chapter 15. Sound Subsystem</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/sound/#oss-intro>15.1. Introduction</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/sound/#oss-files>15.2. Files</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/sound/#pcm-probe-and-attach>15.3. Probing, Attaching, etc.</a></li><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/sound/#oss-interfaces>15.4. Interfaces</a></li></ul></li><li><input type=checkbox id=chapter-41c74c3e72fcf5116f6d999c36ef185b class=toggle>
<label class="icon cursor" for=chapter-41c74c3e72fcf5116f6d999c36ef185b><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/pccard/>Chapter 16. PC Card</a><ul><li><a href=http://172.16.201.134:1313/en/books/arch-handbook/pccard/#pccard-adddev>16.1. Adding a Device</a></li></ul></li><li><input type=checkbox id=chapter-2a7cf37011599a8e3d62d1e3008c3c5d class=toggle>
<label for=chapter-2a7cf37011599a8e3d62d1e3008c3c5d><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/partiii/>Part III. Appendices</a></li><li><input type=checkbox id=chapter-d4c82056f0235da9fde0d29203d44f9a class=toggle>
<label for=chapter-d4c82056f0235da9fde0d29203d44f9a><a role=button></a></label><a href=http://172.16.201.134:1313/en/books/arch-handbook/bibliography/>Bibliography</a></li><li></li></ul></nav></div></aside><div class=book><div class=book-menu-mobile><label for=menu-control><span class=menu-control-button><i class="fa fa-list" aria-hidden=true title="Book menu"></i>
Book menu</span></label></div><h1 class=title>Chapter 8. SMPng Design Document</h1><div class=toc-mobile><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#smp-intro>8.1. Introduction</a></li><li><a href=#smp-lock-fundamentals>8.2. Basic Tools and Locking Fundamentals</a></li><li><a href=#smp-design>8.3. General Architecture and Design</a></li><li><a href=#smp-lock-strategies>8.4. Specific Locking Strategies</a></li><li><a href=#smp-implementation-notes>8.5. Implementation Notes</a></li><li><a href=#smp-misc>8.6. Miscellaneous Topics</a></li><li><a href=#smp-glossary>Glossary</a></li></ul></nav></div><div class=book-content><div id=preamble><div class=sectionbody></div></div><div class=sect1><h2 id=smp-intro>8.1. Introduction<a class=anchor href=#smp-intro></a></h2><div class=sectionbody><div class=paragraph><p>This document presents the current design and implementation of the SMPng Architecture. First, the basic primitives and tools are introduced. Next, a general architecture for the FreeBSD kernelâ€™s synchronization and execution model is laid out. Then, locking strategies for specific subsystems are discussed, documenting the approaches taken to introduce fine-grained synchronization and parallelism for each subsystem. Finally, detailed implementation notes are provided to motivate design choices, and make the reader aware of important implications involving the use of specific primitives.</p></div><div class=paragraph><p>This document is a work-in-progress, and will be updated to reflect on-going design and implementation activities associated with the SMPng Project. Many sections currently exist only in outline form, but will be fleshed out as work proceeds. Updates or suggestions regarding the document may be directed to the document editors.</p></div><div class=paragraph><p>The goal of SMPng is to allow concurrency in the kernel. The kernel is basically
one rather large and complex program. To make the kernel multi-threaded we use
some of the same tools used to make other programs multi-threaded. These include
mutexes, shared/exclusive locks, semaphores, and condition variables. For the
definitions of these and other SMP-related terms, please see the <a href=../smp/#smp-glossary>Glossary</a> section of this article.</p></div></div></div><div class=sect1><h2 id=smp-lock-fundamentals>8.2. Basic Tools and Locking Fundamentals<a class=anchor href=#smp-lock-fundamentals></a></h2><div class=sectionbody><div class=sect2><h3 id=_atomic_instructions_and_memory_barriers>8.2.1. Atomic Instructions and Memory Barriers<a class=anchor href=#_atomic_instructions_and_memory_barriers></a></h3><div class=paragraph><p>There are several existing treatments of memory barriers and atomic instructions, so this section will not include a lot of detail. To put it simply, one can not go around reading variables without a lock if a lock is used to protect writes to that variable. This becomes obvious when you consider that memory barriers simply determine relative order of memory operations; they do not make any guarantee about timing of memory operations. That is, a memory barrier does not force the contents of a CPUâ€™s local cache or store buffer to flush. Instead, the memory barrier at lock release simply ensures that all writes to the protected data will be visible to other CPUâ€™s or devices if the write to release the lock is visible. The CPU is free to keep that data in its cache or store buffer as long as it wants. However, if another CPU performs an atomic instruction on the same datum, the first CPU must guarantee that the updated value is made visible to the second CPU along with any other operations that memory barriers may require.</p></div><div class=paragraph><p>For example, assuming a simple model where data is considered visible when it is in main memory (or a global cache), when an atomic instruction is triggered on one CPU, other CPUâ€™s store buffers and caches must flush any writes to that same cache line along with any pending operations behind a memory barrier.</p></div><div class=paragraph><p>This requires one to take special care when using an item protected by atomic instructions. For example, in the sleep mutex implementation, we have to use an <code>atomic_cmpset</code> rather than an <code>atomic_set</code> to turn on the <code>MTX_CONTESTED</code> bit. The reason is that we read the value of <code>mtx_lock</code> into a variable and then make a decision based on that read. However, the value we read may be stale, or it may change while we are making our decision. Thus, when the <code>atomic_set</code> executed, it may end up setting the bit on another value than the one we made the decision on. Thus, we have to use an <code>atomic_cmpset</code> to set the value only if the value we made the decision on is up-to-date and valid.</p></div><div class=paragraph><p>Finally, atomic instructions only allow one item to be updated or read. If one needs to atomically update several items, then a lock must be used instead. For example, if two counters must be read and have values that are consistent relative to each other, then those counters must be protected by a lock rather than by separate atomic instructions.</p></div></div><div class=sect2><h3 id=_read_locks_versus_write_locks>8.2.2. Read Locks Versus Write Locks<a class=anchor href=#_read_locks_versus_write_locks></a></h3><div class=paragraph><p>Read locks do not need to be as strong as write locks. Both types of locks need to ensure that the data they are accessing is not stale. However, only write access requires exclusive access. Multiple threads can safely read a value. Using different types of locks for reads and writes can be implemented in a number of ways.</p></div><div class=paragraph><p>First, sx locks can be used in this manner by using an exclusive lock when writing and a shared lock when reading. This method is quite straightforward.</p></div><div class=paragraph><p>A second method is a bit more obscure. You can protect a datum with multiple locks. Then for reading that data you simply need to have a read lock of one of the locks. However, to write to the data, you need to have a write lock of all of the locks. This can make writing rather expensive but can be useful when data is accessed in various ways. For example, the parent process pointer is protected by both the <code>proctree_lock</code> sx lock and the per-process mutex. Sometimes the proc lock is easier as we are just checking to see who a parent of a process is that we already have locked. However, other places such as <code>inferior</code> need to walk the tree of processes via parent pointers and locking each process would be prohibitive as well as a pain to guarantee that the condition you are checking remains valid for both the check and the actions taken as a result of the check.</p></div></div><div class=sect2><h3 id=_locking_conditions_and_results>8.2.3. Locking Conditions and Results<a class=anchor href=#_locking_conditions_and_results></a></h3><div class=paragraph><p>If you need a lock to check the state of a variable so that you can take an action based on the state you read, you can not just hold the lock while reading the variable and then drop the lock before you act on the value you read. Once you drop the lock, the variable can change rendering your decision invalid. Thus, you must hold the lock both while reading the variable and while performing the action as a result of the test.</p></div></div></div></div><div class=sect1><h2 id=smp-design>8.3. General Architecture and Design<a class=anchor href=#smp-design></a></h2><div class=sectionbody><div class=sect2><h3 id=_interrupt_handling>8.3.1. Interrupt Handling<a class=anchor href=#_interrupt_handling></a></h3><div class=paragraph><p>Following the pattern of several other multi-threaded UNIXÂ® kernels, FreeBSD deals with interrupt handlers by giving them their own thread context. Providing a context for interrupt handlers allows them to block on locks. To help avoid latency, however, interrupt threads run at real-time kernel priority. Thus, interrupt handlers should not execute for very long to avoid starving other kernel threads. In addition, since multiple handlers may share an interrupt thread, interrupt handlers should not sleep or use a sleepable lock to avoid starving another interrupt handler.</p></div><div class=paragraph><p>The interrupt threads currently in FreeBSD are referred to as heavyweight interrupt threads. They are called this because switching to an interrupt thread involves a full context switch. In the initial implementation, the kernel was not preemptive and thus interrupts that interrupted a kernel thread would have to wait until the kernel thread blocked or returned to userland before they would have an opportunity to run.</p></div><div class=paragraph><p>To deal with the latency problems, the kernel in FreeBSD has been made preemptive. Currently, we only preempt a kernel thread when we release a sleep mutex or when an interrupt comes in. However, the plan is to make the FreeBSD kernel fully preemptive as described below.</p></div><div class=paragraph><p>Not all interrupt handlers execute in a thread context. Instead, some handlers execute directly in primary interrupt context. These interrupt handlers are currently misnamed "fast" interrupt handlers since the <code>INTR_FAST</code> flag used in earlier versions of the kernel is used to mark these handlers. The only interrupts which currently use these types of interrupt handlers are clock interrupts and serial I/O device interrupts. Since these handlers do not have their own context, they may not acquire blocking locks and thus may only use spin mutexes.</p></div><div class=paragraph><p>Finally, there is one optional optimization that can be added in MD code called lightweight context switches. Since an interrupt thread executes in a kernel context, it can borrow the vmspace of any process. Thus, in a lightweight context switch, the switch to the interrupt thread does not switch vmspaces but borrows the vmspace of the interrupted thread. In order to ensure that the vmspace of the interrupted thread does not disappear out from under us, the interrupted thread is not allowed to execute until the interrupt thread is no longer borrowing its vmspace. This can happen when the interrupt thread either blocks or finishes. If an interrupt thread blocks, then it will use its own context when it is made runnable again. Thus, it can release the interrupted thread.</p></div><div class=paragraph><p>The cons of this optimization are that they are very machine specific and complex and thus only worth the effort if their is a large performance improvement. At this point it is probably too early to tell, and in fact, will probably hurt performance as almost all interrupt handlers will immediately block on Giant and require a thread fix-up when they block. Also, an alternative method of interrupt handling has been proposed by Mike Smith that works like so:</p></div><div class="olist arabic"><ol class=arabic><li><p>Each interrupt handler has two parts: a predicate which runs in primary interrupt context and a handler which runs in its own thread context.</p></li><li><p>If an interrupt handler has a predicate, then when an interrupt is triggered, the predicate is run. If the predicate returns true then the interrupt is assumed to be fully handled and the kernel returns from the interrupt. If the predicate returns false or there is no predicate, then the threaded handler is scheduled to run.</p></li></ol></div><div class=paragraph><p>Fitting light weight context switches into this scheme might prove rather complicated. Since we may want to change to this scheme at some point in the future, it is probably best to defer work on light weight context switches until we have settled on the final interrupt handling architecture and determined how light weight context switches might or might not fit into it.</p></div></div><div class=sect2><h3 id=_kernel_preemption_and_critical_sections>8.3.2. Kernel Preemption and Critical Sections<a class=anchor href=#_kernel_preemption_and_critical_sections></a></h3><div class=sect3><h4 id=_kernel_preemption_in_a_nutshell>8.3.2.1. Kernel Preemption in a Nutshell<a class=anchor href=#_kernel_preemption_in_a_nutshell></a></h4><div class=paragraph><p>Kernel preemption is fairly simple. The basic idea is that a CPU should always be doing the highest priority work available. Well, that is the ideal at least. There are a couple of cases where the expense of achieving the ideal is not worth being perfect.</p></div><div class=paragraph><p>Implementing full kernel preemption is very straightforward: when you schedule a thread to be executed by putting it on a run queue, you check to see if its priority is higher than the currently executing thread. If so, you initiate a context switch to that thread.</p></div><div class=paragraph><p>While locks can protect most data in the case of a preemption, not all of the kernel is preemption safe. For example, if a thread holding a spin mutex preempted and the new thread attempts to grab the same spin mutex, the new thread may spin forever as the interrupted thread may never get a chance to execute. Also, some code such as the code to assign an address space number for a process during <code>exec</code> on the Alpha needs to not be preempted as it supports the actual context switch code. Preemption is disabled for these code sections by using a critical section.</p></div></div><div class=sect3><h4 id=_critical_sections>8.3.2.2. Critical Sections<a class=anchor href=#_critical_sections></a></h4><div class=paragraph><p>The responsibility of the critical section API is to prevent context switches inside of a critical section. With a fully preemptive kernel, every <code>setrunqueue</code> of a thread other than the current thread is a preemption point. One implementation is for <code>critical_enter</code> to set a per-thread flag that is cleared by its counterpart. If <code>setrunqueue</code> is called with this flag set, it does not preempt regardless of the priority of the new thread relative to the current thread. However, since critical sections are used in spin mutexes to prevent context switches and multiple spin mutexes can be acquired, the critical section API must support nesting. For this reason the current implementation uses a nesting count instead of a single per-thread flag.</p></div><div class=paragraph><p>In order to minimize latency, preemptions inside of a critical section are deferred rather than dropped. If a thread that would normally be preempted to is made runnable while the current thread is in a critical section, then a per-thread flag is set to indicate that there is a pending preemption. When the outermost critical section is exited, the flag is checked. If the flag is set, then the current thread is preempted to allow the higher priority thread to run.</p></div><div class=paragraph><p>Interrupts pose a problem with regards to spin mutexes. If a low-level interrupt handler needs a lock, it needs to not interrupt any code needing that lock to avoid possible data structure corruption. Currently, providing this mechanism is piggybacked onto critical section API by means of the <code>cpu_critical_enter</code> and <code>cpu_critical_exit</code> functions. Currently this API disables and re-enables interrupts on all of FreeBSDâ€™s current platforms. This approach may not be purely optimal, but it is simple to understand and simple to get right. Theoretically, this second API need only be used for spin mutexes that are used in primary interrupt context. However, to make the code simpler, it is used for all spin mutexes and even all critical sections. It may be desirable to split out the MD API from the MI API and only use it in conjunction with the MI API in the spin mutex implementation. If this approach is taken, then the MD API likely would need a rename to show that it is a separate API.</p></div></div><div class=sect3><h4 id=_design_tradeoffs>8.3.2.3. Design Tradeoffs<a class=anchor href=#_design_tradeoffs></a></h4><div class=paragraph><p>As mentioned earlier, a couple of trade-offs have been made to sacrifice cases where perfect preemption may not always provide the best performance.</p></div><div class=paragraph><p>The first trade-off is that the preemption code does not take other CPUs into account. Suppose we have a two CPUâ€™s A and B with the priority of Aâ€™s thread as 4 and the priority of Bâ€™s thread as 2. If CPU B makes a thread with priority 1 runnable, then in theory, we want CPU A to switch to the new thread so that we will be running the two highest priority runnable threads. However, the cost of determining which CPU to enforce a preemption on as well as actually signaling that CPU via an IPI along with the synchronization that would be required would be enormous. Thus, the current code would instead force CPU B to switch to the higher priority thread. Note that this still puts the system in a better position as CPU B is executing a thread of priority 1 rather than a thread of priority 2.</p></div><div class=paragraph><p>The second trade-off limits immediate kernel preemption to real-time priority kernel threads. In the simple case of preemption defined above, a thread is always preempted immediately (or as soon as a critical section is exited) if a higher priority thread is made runnable. However, many threads executing in the kernel only execute in a kernel context for a short time before either blocking or returning to userland. Thus, if the kernel preempts these threads to run another non-realtime kernel thread, the kernel may switch out the executing thread just before it is about to sleep or execute. The cache on the CPU must then adjust to the new thread. When the kernel returns to the preempted thread, it must refill all the cache information that was lost. In addition, two extra context switches are performed that could be avoided if the kernel deferred the preemption until the first thread blocked or returned to userland. Thus, by default, the preemption code will only preempt immediately if the higher priority thread is a real-time priority thread.</p></div><div class=paragraph><p>Turning on full kernel preemption for all kernel threads has value as a debugging aid since it exposes more race conditions. It is especially useful on UP systems were many races are hard to simulate otherwise. Thus, there is a kernel option <code>FULL_PREEMPTION</code> to enable preemption for all kernel threads that can be used for debugging purposes.</p></div></div></div><div class=sect2><h3 id=_thread_migration>8.3.3. Thread Migration<a class=anchor href=#_thread_migration></a></h3><div class=paragraph><p>Simply put, a thread migrates when it moves from one CPU to another. In a non-preemptive kernel this can only happen at well-defined points such as when calling <code>msleep</code> or returning to userland. However, in the preemptive kernel, an interrupt can force a preemption and possible migration at any time. This can have negative affects on per-CPU data since with the exception of <code>curthread</code> and <code>curpcb</code> the data can change whenever you migrate. Since you can potentially migrate at any time this renders unprotected per-CPU data access rather useless. Thus it is desirable to be able to disable migration for sections of code that need per-CPU data to be stable.</p></div><div class=paragraph><p>Critical sections currently prevent migration since they do not allow context switches. However, this may be too strong of a requirement to enforce in some cases since a critical section also effectively blocks interrupt threads on the current processor. As a result, another API has been provided to allow the current thread to indicate that if it preempted it should not migrate to another CPU.</p></div><div class=paragraph><p>This API is known as thread pinning and is provided by the scheduler. The API consists of two functions: <code>sched_pin</code> and <code>sched_unpin</code>. These functions manage a per-thread nesting count <code>td_pinned</code>. A thread is pinned when its nesting count is greater than zero and a thread starts off unpinned with a nesting count of zero. Each scheduler implementation is required to ensure that pinned threads are only executed on the CPU that they were executing on when the <code>sched_pin</code> was first called. Since the nesting count is only written to by the thread itself and is only read by other threads when the pinned thread is not executing but while <code>sched_lock</code> is held, then <code>td_pinned</code> does not need any locking. The <code>sched_pin</code> function increments the nesting count and <code>sched_unpin</code> decrements the nesting count. Note that these functions only operate on the current thread and bind the current thread to the CPU it is executing on at the time. To bind an arbitrary thread to a specific CPU, the <code>sched_bind</code> and <code>sched_unbind</code> functions should be used instead.</p></div></div><div class=sect2><h3 id=_callouts>8.3.4. Callouts<a class=anchor href=#_callouts></a></h3><div class=paragraph><p>The <code>timeout</code> kernel facility permits kernel services to register functions for execution as part of the <code>softclock</code> software interrupt. Events are scheduled based on a desired number of clock ticks, and callbacks to the consumer-provided function will occur at approximately the right time.</p></div><div class=paragraph><p>The global list of pending timeout events is protected by a global spin mutex, <code>callout_lock</code>; all access to the timeout list must be performed with this mutex held. When <code>softclock</code> is woken up, it scans the list of pending timeouts for those that should fire. In order to avoid lock order reversal, the <code>softclock</code> thread will release the <code>callout_lock</code> mutex when invoking the provided <code>timeout</code> callback function. If the <code>CALLOUT_MPSAFE</code> flag was not set during registration, then Giant will be grabbed before invoking the callout, and then released afterwards. The <code>callout_lock</code> mutex will be re-grabbed before proceeding. The <code>softclock</code> code is careful to leave the list in a consistent state while releasing the mutex. If <code>DIAGNOSTIC</code> is enabled, then the time taken to execute each function is measured, and a warning is generated if it exceeds a threshold.</p></div></div></div></div><div class=sect1><h2 id=smp-lock-strategies>8.4. Specific Locking Strategies<a class=anchor href=#smp-lock-strategies></a></h2><div class=sectionbody><div class=sect2><h3 id=_credentials>8.4.1. Credentials<a class=anchor href=#_credentials></a></h3><div class=paragraph><p><code>struct ucred</code> is the kernelâ€™s internal credential structure, and is generally used as the basis for process-driven access control within the kernel. BSD-derived systems use a "copy-on-write" model for credential data: multiple references may exist for a credential structure, and when a change needs to be made, the structure is duplicated, modified, and then the reference replaced. Due to wide-spread caching of the credential to implement access control on open, this results in substantial memory savings. With a move to fine-grained SMP, this model also saves substantially on locking operations by requiring that modification only occur on an unshared credential, avoiding the need for explicit synchronization when consuming a known-shared credential.</p></div><div class=paragraph><p>Credential structures with a single reference are considered mutable; shared credential structures must not be modified or a race condition is risked. A mutex, <code>cr_mtxp</code> protects the reference count of <code>struct ucred</code> so as to maintain consistency. Any use of the structure requires a valid reference for the duration of the use, or the structure may be released out from under the illegitimate consumer.</p></div><div class=paragraph><p>The <code>struct ucred</code> mutex is a leaf mutex and is implemented via a mutex pool for performance reasons.</p></div><div class=paragraph><p>Usually, credentials are used in a read-only manner for access control decisions, and in this case <code>td_ucred</code> is generally preferred because it requires no locking. When a process' credential is updated the <code>proc</code> lock must be held across the check and update operations thus avoid races. The process credential <code>p_ucred</code> must be used for check and update operations to prevent time-of-check, time-of-use races.</p></div><div class=paragraph><p>If system call invocations will perform access control after an update to the process credential, the value of <code>td_ucred</code> must also be refreshed to the current process value. This will prevent use of a stale credential following a change. The kernel automatically refreshes the <code>td_ucred</code> pointer in the thread structure from the process <code>p_ucred</code> whenever a process enters the kernel, permitting use of a fresh credential for kernel access control.</p></div></div><div class=sect2><h3 id=_file_descriptors_and_file_descriptor_tables>8.4.2. File Descriptors and File Descriptor Tables<a class=anchor href=#_file_descriptors_and_file_descriptor_tables></a></h3><div class=paragraph><p>Details to follow.</p></div></div><div class=sect2><h3 id=_jail_structures>8.4.3. Jail Structures<a class=anchor href=#_jail_structures></a></h3><div class=paragraph><p><code>struct prison</code> stores administrative details pertinent to the maintenance of jails created using the <a href="https://man.freebsd.org/cgi/man.cgi?query=jail&amp;sektion=2&amp;format=html">jail(2)</a> API. This includes the per-jail hostname, IP address, and related settings. This structure is reference-counted since pointers to instances of the structure are shared by many credential structures. A single mutex, <code>pr_mtx</code> protects read and write access to the reference count and all mutable variables inside the struct jail. Some variables are set only when the jail is created, and a valid reference to the <code>struct prison</code> is sufficient to read these values. The precise locking of each entry is documented via comments in <span class=filename>sys/jail.h</span>.</p></div></div><div class=sect2><h3 id=_mac_framework>8.4.4. MAC Framework<a class=anchor href=#_mac_framework></a></h3><div class=paragraph><p>The TrustedBSD MAC Framework maintains data in a variety of kernel objects, in the form of <code>struct label</code>. In general, labels in kernel objects are protected by the same lock as the remainder of the kernel object. For example, the <code>v_label</code> label in <code>struct vnode</code> is protected by the vnode lock on the vnode.</p></div><div class=paragraph><p>In addition to labels maintained in standard kernel objects, the MAC Framework also maintains a list of registered and active policies. The policy list is protected by a global mutex (<code>mac_policy_list_lock</code>) and a busy count (also protected by the mutex). Since many access control checks may occur in parallel, entry to the framework for a read-only access to the policy list requires holding the mutex while incrementing (and later decrementing) the busy count. The mutex need not be held for the duration of the MAC entry operationâ€”â€‹some operations, such as label operations on file system objectsâ€”â€‹are long-lived. To modify the policy list, such as during policy registration and de-registration, the mutex must be held and the reference count must be zero, to prevent modification of the list while it is in use.</p></div><div class=paragraph><p>A condition variable, <code>mac_policy_list_not_busy</code>, is available to threads that need to wait for the list to become unbusy, but this condition variable must only be waited on if the caller is holding no other locks, or a lock order violation may be possible. The busy count, in effect, acts as a form of shared/exclusive lock over access to the framework: the difference is that, unlike with an sx lock, consumers waiting for the list to become unbusy may be starved, rather than permitting lock order problems with regards to the busy count and other locks that may be held on entry to (or inside) the MAC Framework.</p></div></div><div class=sect2><h3 id=_modules>8.4.5. Modules<a class=anchor href=#_modules></a></h3><div class=paragraph><p>For the module subsystem there exists a single lock that is used to protect the shared data. This lock is a shared/exclusive (SX) lock and has a good chance of needing to be acquired (shared or exclusively), therefore there are a few macros that have been added to make access to the lock more easy. These macros can be located in <span class=filename>sys/module.h</span> and are quite basic in terms of usage. The main structures protected under this lock are the <code>module_t</code> structures (when shared) and the global <code>modulelist_t</code> structure, modules. One should review the related source code in <span class=filename>kern/kern_module.c</span> to further understand the locking strategy.</p></div></div><div class=sect2><h3 id=_newbus_device_tree>8.4.6. Newbus Device Tree<a class=anchor href=#_newbus_device_tree></a></h3><div class=paragraph><p>The newbus system will have one sx lock. Readers will hold a shared (read) lock (<a href="https://man.freebsd.org/cgi/man.cgi?query=sx_slock&amp;sektion=9&amp;format=html">sx_slock(9)</a>) and writers will hold an exclusive (write) lock (<a href="https://man.freebsd.org/cgi/man.cgi?query=sx_xlock&amp;sektion=9&amp;format=html">sx_xlock(9)</a>). Internal functions will not do locking at all. Externally visible ones will lock as needed. Those items that do not matter if the race is won or lost will not be locked, since they tend to be read all over the place (e.g., <a href="https://man.freebsd.org/cgi/man.cgi?query=device_get_softc&amp;sektion=9&amp;format=html">device_get_softc(9)</a>). There will be relatively few changes to the newbus data structures, so a single lock should be sufficient and not impose a performance penalty.</p></div></div><div class=sect2><h3 id=_pipes>8.4.7. Pipes<a class=anchor href=#_pipes></a></h3><div class=paragraph><p>â€¦â€‹</p></div></div><div class=sect2><h3 id=_processes_and_threads>8.4.8. Processes and Threads<a class=anchor href=#_processes_and_threads></a></h3><div class=ulist><ul><li><p>process hierarchy</p></li><li><p>proc locks, references</p></li><li><p>thread-specific copies of proc entries to freeze during system calls, including td_ucred</p></li><li><p>inter-process operations</p></li><li><p>process groups and sessions</p></li></ul></div></div><div class=sect2><h3 id=_scheduler>8.4.9. Scheduler<a class=anchor href=#_scheduler></a></h3><div class=paragraph><p>Lots of references to <code>sched_lock</code> and notes pointing at specific primitives and related magic elsewhere in the document.</p></div></div><div class=sect2><h3 id=_select_and_poll>8.4.10. Select and Poll<a class=anchor href=#_select_and_poll></a></h3><div class=paragraph><p>The <code>select</code> and <code>poll</code> functions permit threads to block waiting on events on file descriptorsâ€”â€‹most frequently, whether or not the file descriptors are readable or writable.</p></div><div class=paragraph><p>â€¦â€‹</p></div></div><div class=sect2><h3 id=_sigio>8.4.11. SIGIO<a class=anchor href=#_sigio></a></h3><div class=paragraph><p>The SIGIO service permits processes to request the delivery of a SIGIO signal to its process group when the read/write status of specified file descriptors changes. At most one process or process group is permitted to register for SIGIO from any given kernel object, and that process or group is referred to as the owner. Each object supporting SIGIO registration contains pointer field that is <code>NULL</code> if the object is not registered, or points to a <code>struct sigio</code> describing the registration. This field is protected by a global mutex, <code>sigio_lock</code>. Callers to SIGIO maintenance functions must pass in this field "by reference" so that local register copies of the field are not made when unprotected by the lock.</p></div><div class=paragraph><p>One <code>struct sigio</code> is allocated for each registered object associated with any process or process group, and contains back-pointers to the object, owner, signal information, a credential, and the general disposition of the registration. Each process or progress group contains a list of registered <code>struct sigio</code> structures, <code>p_sigiolst</code> for processes, and <code>pg_sigiolst</code> for process groups. These lists are protected by the process or process group locks respectively. Most fields in each <code>struct sigio</code> are constant for the duration of the registration, with the exception of the <code>sio_pgsigio</code> field which links the <code>struct sigio</code> into the process or process group list. Developers implementing new kernel objects supporting SIGIO will, in general, want to avoid holding structure locks while invoking SIGIO supporting functions, such as <code>fsetown</code> or <code>funsetown</code> to avoid defining a lock order between structure locks and the global SIGIO lock. This is generally possible through use of an elevated reference count on the structure, such as reliance on a file descriptor reference to a pipe during a pipe operation.</p></div></div><div class=sect2><h3 id=_sysctl>8.4.12. Sysctl<a class=anchor href=#_sysctl></a></h3><div class=paragraph><p>The <code>sysctl</code> MIB service is invoked from both within the kernel and from userland applications using a system call. At least two issues are raised in locking: first, the protection of the structures maintaining the namespace, and second, interactions with kernel variables and functions that are accessed by the sysctl interface. Since sysctl permits the direct export (and modification) of kernel statistics and configuration parameters, the sysctl mechanism must become aware of appropriate locking semantics for those variables. Currently, sysctl makes use of a single global sx lock to serialize use of <code>sysctl</code>; however, it is assumed to operate under Giant and other protections are not provided. The remainder of this section speculates on locking and semantic changes to sysctl.</p></div><div class=ulist><ul><li><p>Need to change the order of operations for sysctlâ€™s that update values from read old, copyin and copyout, write new to copyin, lock, read old and write new, unlock, copyout. Normal sysctlâ€™s that just copyout the old value and set a new value that they copyin may still be able to follow the old model. However, it may be cleaner to use the second model for all of the sysctl handlers to avoid lock operations.</p></li><li><p>To allow for the common case, a sysctl could embed a pointer to a mutex in the SYSCTL_FOO macros and in the struct. This would work for most sysctlâ€™s. For values protected by sx locks, spin mutexes, or other locking strategies besides a single sleep mutex, SYSCTL_PROC nodes could be used to get the locking right.</p></li></ul></div></div><div class=sect2><h3 id=_taskqueue>8.4.13. Taskqueue<a class=anchor href=#_taskqueue></a></h3><div class=paragraph><p>The taskqueueâ€™s interface has two basic locks associated with it in order to protect the related shared data. The <code>taskqueue_queues_mutex</code> is meant to serve as a lock to protect the <code>taskqueue_queues</code> TAILQ. The other mutex lock associated with this system is the one in the <code>struct taskqueue</code> data structure. The use of the synchronization primitive here is to protect the integrity of the data in the <code>struct taskqueue</code>. It should be noted that there are no separate macros to assist the user in locking down his/her own work since these locks are most likely not going to be used outside of <span class=filename>kern/subr_taskqueue.c</span>.</p></div></div></div></div><div class=sect1><h2 id=smp-implementation-notes>8.5. Implementation Notes<a class=anchor href=#smp-implementation-notes></a></h2><div class=sectionbody><div class=sect2><h3 id=_sleep_queues>8.5.1. Sleep Queues<a class=anchor href=#_sleep_queues></a></h3><div class=paragraph><p>A sleep queue is a structure that holds the list of threads asleep on a wait channel. Each thread that is not asleep on a wait channel carries a sleep queue structure around with it. When a thread blocks on a wait channel, it donates its sleep queue structure to that wait channel. Sleep queues associated with a wait channel are stored in a hash table.</p></div><div class=paragraph><p>The sleep queue hash table holds sleep queues for wait channels that have at least one blocked thread. Each entry in the hash table is called a sleepqueue chain. The chain contains a linked list of sleep queues and a spin mutex. The spin mutex protects the list of sleep queues as well as the contents of the sleep queue structures on the list. Only one sleep queue is associated with a given wait channel. If multiple threads block on a wait channel than the sleep queues associated with all but the first thread are stored on a list of free sleep queues in the master sleep queue. When a thread is removed from the sleep queue it is given one of the sleep queue structures from the master queueâ€™s free list if it is not the only thread asleep on the queue. The last thread is given the master sleep queue when it is resumed. Since threads may be removed from the sleep queue in a different order than they are added, a thread may depart from a sleep queue with a different sleep queue structure than the one it arrived with.</p></div><div class=paragraph><p>The <code>sleepq_lock</code> function locks the spin mutex of the sleep queue chain that maps to a specific wait channel. The <code>sleepq_lookup</code> function looks in the hash table for the master sleep queue associated with a given wait channel. If no master sleep queue is found, it returns <code>NULL</code>. The <code>sleepq_release</code> function unlocks the spin mutex associated with a given wait channel.</p></div><div class=paragraph><p>A thread is added to a sleep queue via the <code>sleepq_add</code>. This function accepts the wait channel, a pointer to the mutex that protects the wait channel, a wait message description string, and a mask of flags. The sleep queue chain should be locked via <code>sleepq_lock</code> before this function is called. If no mutex protects the wait channel (or it is protected by Giant), then the mutex pointer argument should be <code>NULL</code>. The flags argument contains a type field that indicates the kind of sleep queue that the thread is being added to and a flag to indicate if the sleep is interruptible (<code>SLEEPQ_INTERRUPTIBLE</code>). Currently there are only two types of sleep queues: traditional sleep queues managed via the <code>msleep</code> and <code>wakeup</code> functions (<code>SLEEPQ_MSLEEP</code>) and condition variable sleep queues (<code>SLEEPQ_CONDVAR</code>). The sleep queue type and lock pointer argument are used solely for internal assertion checking. Code that calls <code>sleepq_add</code> should explicitly unlock any interlock protecting the wait channel after the associated sleepqueue chain has been locked via <code>sleepq_lock</code> and before blocking on the sleep queue via one of the waiting functions.</p></div><div class=paragraph><p>A timeout for a sleep is set by invoking <code>sleepq_set_timeout</code>. The function accepts the wait channel and the timeout time as a relative tick count as its arguments. If a sleep should be interrupted by arriving signals, the <code>sleepq_catch_signals</code> function should be called as well. This function accepts the wait channel as its only parameter. If there is already a signal pending for this thread, then <code>sleepq_catch_signals</code> will return a signal number; otherwise, it will return 0.</p></div><div class=paragraph><p>Once a thread has been added to a sleep queue, it blocks using one of the <code>sleepq_wait</code> functions. There are four wait functions depending on whether or not the caller wishes to use a timeout or have the sleep aborted by caught signals or an interrupt from the userland thread scheduler. The <code>sleepq_wait</code> function simply waits until the current thread is explicitly resumed by one of the wakeup functions. The <code>sleepq_timedwait</code> function waits until either the thread is explicitly resumed or the timeout set by an earlier call to <code>sleepq_set_timeout</code> expires. The <code>sleepq_wait_sig</code> function waits until either the thread is explicitly resumed or its sleep is aborted. The <code>sleepq_timedwait_sig</code> function waits until either the thread is explicitly resumed, the timeout set by an earlier call to <code>sleepq_set_timeout</code> expires, or the threadâ€™s sleep is aborted. All of the wait functions accept the wait channel as their first parameter. In addition, the <code>sleepq_timedwait_sig</code> function accepts a second boolean parameter to indicate if the earlier call to <code>sleepq_catch_signals</code> found a pending signal.</p></div><div class=paragraph><p>If the thread is explicitly resumed or is aborted by a signal, then a value of zero is returned by the wait function to indicate a successful sleep. If the thread is resumed by either a timeout or an interrupt from the userland thread scheduler then an appropriate errno value is returned instead. Note that since <code>sleepq_wait</code> can only return 0 it does not return anything and the caller should assume a successful sleep. Also, if a threadâ€™s sleep times out and is aborted simultaneously then <code>sleepq_timedwait_sig</code> will return an error indicating that a timeout occurred. If an error value of 0 is returned and either <code>sleepq_wait_sig</code> or <code>sleepq_timedwait_sig</code> was used to block, then the function <code>sleepq_calc_signal_retval</code> should be called to check for any pending signals and calculate an appropriate return value if any are found. The signal number returned by the earlier call to <code>sleepq_catch_signals</code> should be passed as the sole argument to <code>sleepq_calc_signal_retval</code>.</p></div><div class=paragraph><p>Threads asleep on a wait channel are explicitly resumed by the <code>sleepq_broadcast</code> and <code>sleepq_signal</code> functions. Both functions accept the wait channel from which to resume threads, a priority to raise resumed threads to, and a flags argument to indicate which type of sleep queue is being resumed. The priority argument is treated as a minimum priority. If a thread being resumed already has a higher priority (numerically lower) than the priority argument then its priority is not adjusted. The flags argument is used for internal assertions to ensure that sleep queues are not being treated as the wrong type. For example, the condition variable functions should not resume threads on a traditional sleep queue. The <code>sleepq_broadcast</code> function resumes all threads that are blocked on the specified wait channel while <code>sleepq_signal</code> only resumes the highest priority thread blocked on the wait channel. The sleep queue chain should first be locked via the <code>sleepq_lock</code> function before calling these functions.</p></div><div class=paragraph><p>A sleeping thread may have its sleep interrupted by calling the <code>sleepq_abort</code> function. This function must be called with <code>sched_lock</code> held and the thread must be queued on a sleep queue. A thread may also be removed from a specific sleep queue via the <code>sleepq_remove</code> function. This function accepts both a thread and a wait channel as an argument and only awakens the thread if it is on the sleep queue for the specified wait channel. If the thread is not on a sleep queue or it is on a sleep queue for a different wait channel, then this function does nothing.</p></div></div><div class=sect2><h3 id=_turnstiles>8.5.2. Turnstiles<a class=anchor href=#_turnstiles></a></h3><div class=ulist><ul><li><p>Compare/contrast with sleep queues.</p></li><li><p>Lookup/wait/release. - Describe TDF_TSNOBLOCK race.</p></li><li><p>Priority propagation.</p></li></ul></div></div><div class=sect2><h3 id=_details_of_the_mutex_implementation>8.5.3. Details of the Mutex Implementation<a class=anchor href=#_details_of_the_mutex_implementation></a></h3><div class=ulist><ul><li><p>Should we require mutexes to be owned for mtx_destroy() since we can not safely assert that they are unowned by anyone else otherwise?</p></li></ul></div><div class=sect3><h4 id=_spin_mutexes>8.5.3.1. Spin Mutexes<a class=anchor href=#_spin_mutexes></a></h4><div class=ulist><ul><li><p>Use a critical sectionâ€¦â€‹</p></li></ul></div></div><div class=sect3><h4 id=_sleep_mutexes>8.5.3.2. Sleep Mutexes<a class=anchor href=#_sleep_mutexes></a></h4><div class=ulist><ul><li><p>Describe the races with contested mutexes</p></li><li><p>Why it is safe to read mtx_lock of a contested mutex when holding the turnstile chain lock.</p></li></ul></div></div></div><div class=sect2><h3 id=_witness>8.5.4. Witness<a class=anchor href=#_witness></a></h3><div class=ulist><ul><li><p>What does it do</p></li><li><p>How does it work</p></li></ul></div></div></div></div><div class=sect1><h2 id=smp-misc>8.6. Miscellaneous Topics<a class=anchor href=#smp-misc></a></h2><div class=sectionbody><div class=sect2><h3 id=_interrupt_source_and_icu_abstractions>8.6.1. Interrupt Source and ICU Abstractions<a class=anchor href=#_interrupt_source_and_icu_abstractions></a></h3><div class=ulist><ul><li><p>struct isrc</p></li><li><p>pic drivers</p></li></ul></div></div><div class=sect2><h3 id=_other_random_questionstopics>8.6.2. Other Random Questions/Topics<a class=anchor href=#_other_random_questionstopics></a></h3><div class=ulist><ul><li><p>Should we pass an interlock into <code>sema_wait</code>?</p></li><li><p>Should we have non-sleepable sx locks?</p></li><li><p>Add some info about proper use of reference counts.</p></li></ul></div></div></div></div><div class=sect1><h2 id=smp-glossary>Glossary<a class=anchor href=#smp-glossary></a></h2><div class=sectionbody><div class="dlist glosslist"><dl><dt class=hdlist1>atomic</dt><dd><p>An operation is atomic if all of its effects are visible to other CPUs together when the proper access protocol is followed. In the degenerate case are atomic instructions provided directly by machine architectures. At a higher level, if several members of a structure are protected by a lock, then a set of operations are atomic if they are all performed while holding the lock without releasing the lock in between any of the operations.</p><div class=paragraph><p>See Also operation.</p></div></dd><dt class=hdlist1>block</dt><dd><p>A thread is blocked when it is waiting on a lock, resource, or condition. Unfortunately this term is a bit overloaded as a result.</p><div class=paragraph><p>See Also sleep.</p></div></dd><dt class=hdlist1>critical section</dt><dd><p>A section of code that is not allowed to be preempted. A critical section is entered and exited using the <a href="https://man.freebsd.org/cgi/man.cgi?query=critical_enter&amp;sektion=9&amp;format=html">critical_enter(9)</a> API.</p></dd><dt class=hdlist1>MD</dt><dd><p>Machine dependent.</p><div class=paragraph><p>See Also MI.</p></div></dd><dt class=hdlist1>memory operation</dt><dd><p>A memory operation reads and/or writes to a memory location.</p></dd><dt class=hdlist1>MI</dt><dd><p>Machine independent.</p><div class=paragraph><p>See Also MD.</p></div></dd><dt class=hdlist1>operation</dt><dd><p>See memory operation.</p></dd><dt class=hdlist1>primary interrupt context</dt><dd><p>Primary interrupt context refers to the code that runs when an interrupt occurs. This code can either run an interrupt handler directly or schedule an asynchronous interrupt thread to execute the interrupt handlers for a given interrupt source.</p></dd><dt class=hdlist1>realtime kernel thread</dt><dd><p>A high priority kernel thread. Currently, the only realtime priority kernel threads are interrupt threads.</p><div class=paragraph><p>See Also thread.</p></div></dd><dt class=hdlist1>sleep</dt><dd><p>A thread is asleep when it is blocked on a condition variable or a sleep queue via msleep or tsleep.</p><div class=paragraph><p>See Also block.</p></div></dd><dt class=hdlist1>sleepable lock</dt><dd><p>A sleepable lock is a lock that can be held by a thread which is asleep. Lockmgr locks and sx locks are currently the only sleepable locks in FreeBSD. Eventually, some sx locks such as the allproc and proctree locks may become non-sleepable locks.</p><div class=paragraph><p>See Also sleep.</p></div></dd><dt class=hdlist1>thread</dt><dd><p>A kernel thread represented by a struct thread. Threads own locks and hold a single execution context.</p></dd><dt class=hdlist1>wait channel</dt><dd><p>A kernel virtual address that threads may sleep on.</p></dd></dl></div></div></div></div><hr><div class=last-modified><p><strong>Last modified on</strong>: September 20, 2024 by <a href="https://cgit.freebsd.org/doc/commit/?id=2d2f5d38cc" target=_blank>Fernando ApesteguÃ­a</a></p></div><div class=buttons><div class=prev><i class="fa fa-angle-left" aria-hidden=true title=Prev></i><div class=container><a href=http://172.16.201.134:1313/en/books/arch-handbook/vm class=direction>Prev</a></div></div><div class=home><i class="fa fa-home" aria-hidden=true title=Home></i><div class=container><a href=../ class=direction>Home</a></div></div><div class=next><div class=container><a href=http://172.16.201.134:1313/en/books/arch-handbook/partii class=direction>Next</a></div><i class="fa fa-angle-right" aria-hidden=true title=Next></i></div></div><label class="hidden book-menu-overlay" for=menu-control></label></div><aside class=toc><div class=toc-content><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#smp-intro>8.1. Introduction</a></li><li><a href=#smp-lock-fundamentals>8.2. Basic Tools and Locking Fundamentals</a></li><li><a href=#smp-design>8.3. General Architecture and Design</a></li><li><a href=#smp-lock-strategies>8.4. Specific Locking Strategies</a></li><li><a href=#smp-implementation-notes>8.5. Implementation Notes</a></li><li><a href=#smp-misc>8.6. Miscellaneous Topics</a></li><li><a href=#smp-glossary>Glossary</a></li></ul></nav><hr><div class=resources><h3>Resources</h3><ul class=contents><li><i class="fa fa-file-pdf-o" aria-hidden=true title="Download PDF"></i><a href=https://download.freebsd.org/doc/en/books/arch-handbook/arch-handbook_en.pdf>Download PDF</a></li><li><i class="fa fa-pencil-square-o" aria-hidden=true title="Edit this page"></i><a href=https://github.com/freebsd/freebsd-doc/blob/main/documentation/content/en/_index target=_blank>Edit this page</a></li></ul></div></div></aside><a class=to-top href=#top><i class="fa fa-arrow-circle-up" aria-hidden=true></i></a></main><footer><div class=footer-container><section class=logo-column><img src=http://172.16.201.134:1313/images/FreeBSD-colors.svg width=160 height=50 alt="FreeBSD logo"><div class=options-container><div class=language-container><a id=languages href=http://172.16.201.134:1313/en/languages><img src=http://172.16.201.134:1313/images/language.png class=language-image alt="Choose language">
<span>English</span></a></div><div class=theme-container><select id=theme-chooser><option value=theme-system>System</option><option value=theme-light>Light</option><option value=theme-dark>Dark</option><option value=theme-high-contrast>High contrast</option></select></div></div></section><section class=about-column><h3 class=column-title>About</h3><ul class=column-elements-container><li><a href=https://www.freebsd.org/about/ target=_blank class=column-element>FreeBSD</a></li><li><a href=https://freebsdfoundation.org/ target=_blank class=column-element>FreeBSD Foundation</a></li><li><a href=https://www.freebsd.org/where/ target=_blank class=column-element>Get FreeBSD</a></li><li><a href=https://www.freebsd.org/internal/code-of-conduct target=_blank class=column-element>Code of Conduct</a></li><li><a href=https://www.freebsd.org/security/ target=_blank class=column-element>Security Advisories</a></li></ul></section><section class=documentation-column><h3 class=column-title>Documentation</h3><ul class=column-elements-container><li><a href=/en class=column-element>Documentation portal</a></li><li><a href=https://man.FreeBSD.org target=_blank class=column-element>Manual pages</a></li><li><a href=https://papers.FreeBSD.org target=_blank class=column-element>Presentations and papers</a></li><li><a href=https://docs-archive.freebsd.org/doc/ target=_blank class=column-element>Previous versions</a></li><li><a href=https://docs-archive.freebsd.org/44doc/ target=_blank class=column-element>4.4BSD Documents</a></li><li><a href=https://wiki.freebsd.org/ target=_blank class=column-element>Wiki</a></li></ul></section><section class=community-column><h3 class=column-title>Community</h3><ul class=column-elements-container><li><a href=http://172.16.201.134:1313/en/articles/contributing class=column-element>Get involved</a></li><li><a href=https://forums.freebsd.org/ target=_blank class=column-element>Community forum</a></li><li><a href=https://lists.freebsd.org/ target=_blank class=column-element>Mailing lists</a></li><li><a href=https://wiki.freebsd.org/IRC/Channels target=_blank class=column-element>IRC Channels</a></li><li><a href=https://bugs.freebsd.org/bugzilla/ target=_blank class=column-element>Bug Tracker</a></li></ul></section><section class=legal-column><h3 class=column-title>Legal</h3><ul class=column-elements-container><li><a href=https://freebsdfoundation.org/donate/ target=_blank class=column-element>Donations</a></li><li><a href=https://www.freebsd.org/copyright/freebsd-license/ target=_blank class=column-element>Licensing</a></li><li><a href=https://www.freebsd.org/privacy/ target=_blank class=column-element>Privacy Policy</a></li><li><a href=https://www.freebsd.org/copyright/ target=_blank class=column-element>Legal notices</a></li></ul></section><section class=copyright-column><p>&copy; 1994-2024 The FreeBSD Project. All rights reserved</p><span>Made with <span class=heart>â™¥</span> by the FreeBSD Community</span></section></div></footer></body></html>